# @package _global_
animation_mode: Video Source
video_path: /home/dmarx/proj/pytti-book/reefer_madness.mp4
#video_path: /home/dmarx/proj/pytti-core/src/pytti/assets/HebyMorgongava_512kb.mp4
#video_path: /home/dmarx/proj/pytti-book/train_trimmed.mp4

# Wish I could just softmax these variables...
# scenes: "a photograph of a beautiful spring day:2 | morning:fLo | sunset:(1-fLo) | flowers:fHi | leaves:(1-fHi)"
scenes: "a photograph of a beautiful spring day:2 | morning:fLo/(fLo+fHi) | sunset:(1-fLo/(fLo+fHi) ) | flowers:fHi/(fLo+fHi) | leaves:(1 - fHi/(fLo+fHi) )"


#image_model: Unlimited Palette
image_model: VQGAN
vqgan_model: imagenet

#height: 400
#width: 400

height: 100
width: 100

backups: 5

# maybe this is what was breaking roto? ...nope
pre_animation_steps: 0

use_tensorboard: true


approximate_vram_usage: false

## semantic masking, prompt will be applied to image subject
#scenes: colorful mandelbrot fractal_/home/dmarx/proj/pytti-book/reefer_madness.mp4

# direct masking, prompt will be applied to white areas #... basically no different.
#scenes: colorful mandelbrot fractal_[/home/dmarx/proj/pytti-book/reefer_madness.mp4]
# maybe would work better with a semantic image prompt?

# broken because hydra...
#scenes: colorful mandelbrot fractal | /home/dmarx/proj/pytti-book/reefer_madness.mp4
#scenes: color photograph of two people in a room
#scenes: color photograph of two people in a room | black and white photo:-0.1 # colorful mandelbrot fractal
#scenes: a colorful van gogh painting

#scenes: "/home/dmarx/proj/pytti-book/train_trimmed.mp4"
#scenes: "a photograph of a beautiful spring day:2 ||  a photograph of a snowy winter day:2 "
#scenes: "a photograph of a beautiful spring day:2 | morning:fLo | sunset:(1-fLo) | flowers:fHi | leaves:(1-fHi)"
#scenes: "'[/home/dmarx/proj/pytti-book/reefer_madness.mp4]' | national geographic beautiful spring bloom photography: '(fLo*2)**2'"
#scenes: "[/home/dmarx/proj/pytti-book/reefer_madness.mp4] | national geographic beautiful spring bloom photography: '(fLo*2)**2'"
#cut_pow: 1.5
cutouts: 80
#gradient_accumulation_steps: 2

reencode_each_frame: false
#reencode_each_frame: true

# 10 seconds * 12 fps * 80 steps/frame = 6000 steps
steps_per_scene: 6000

# 12 fps * 3s * 80 steps/frame = 2400 steps
interpolation_steps: 2400

#steps_per_scene: 50000 # whatever... I really do need to fix this.
#steps_per_frame: 50 #50*(1 + (1+sin(t))**2)
#steps_per_frame: 50

# might need to parameterized_eval these
#steps_per_frame: int(200*fLo - 195*(1-fLo))
#save_every: int(200*fLo - 195*(1-fLo))

# really. is *learning rate* not a paramterized_eval-able param??? fuck my life...
# yeah I gues that would have to be a scheduler or something...?
#learning_rate: .01 + .04*fLo
steps_per_frame: 50
save_every: 50

# by far simplest thing is to play with prompt weights....


#save_every: 50 # why is this a different setting from steps per frame?
#display_every: 1000000000000000 # this is probably why I wasn't seeing tensorboard outputs
display_every: 50
#direct_stabilization_weight: 2*(1 + (1+sin(t))**2)
#semantic_stabilization_weight: 5 # this is what was fucking it up.
#semantic_stabilization_weight: 0.5 # let's try adding a light semantic weight
#semantic_stabilization_weight: 1
direct_stabilization_weight: .5 #1
flow_stabilization_weight: 1
flow_long_term_samples: 2
frame_stride: 2
#depth_stabilization_weight: 1
#direct_init_weight: 1

#reencode_each_frame: true

file_namespace: audio_test


input_audio: '/home/dmarx/proj/pytti-book/reefer_madness.mp4'
input_audio_offset: 0

## 'input_audio_filters': {'f_width': 1, 'f_center': 1}
##offset = filter.f_width / 2
##AttributeError: 'str' object has no attribute 'f_width'
#input_audio_filters:
#  f_width: 1
#  f_center: 1

##  'input_audio_filters': [{'f_width': 1}, {'f_center': 1}]}
##omegaconf.errors.ConfigAttributeError: Key 'f_center' is not in struct
##    full_key: input_audio_filters[0].f_center
##    object_type=dict
#input_audio_filters:
#- f_width: 1
#- f_center: 1


## yaml.scanner.ScannerError: mapping values are not allowed here
##   in "/home/dmarx/proj/pytti-core/config/conf/cblfb_audio_input_test.yaml", line 96, column 13
#input_audio_filters:
#  - variable_name fLo
#    f_center: 60
#    f_width: 30
#    order: 5

## yaml.scanner.ScannerError: mapping values are not allowed here
##   in "/home/dmarx/proj/pytti-core/config/conf/cblfb_audio_input_test.yaml", line 106, column 11
#input_audio_filters:
#- variable_name fLo
#  f_center: 60
#  f_width: 30
#  order: 5

input_audio_filters:
- variable_name: fLo
  f_center: 60
  f_width: 30
  order: 5
- variable_name: fHi
  f_center: 1500
  f_width: 500
  order: 5 # what does order do?



RN50: true
#ViTB32: true
ViTB32: false
